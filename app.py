from flask import Flask, render_template, request, jsonify
import os, json, random, re, asyncio, math, unicodedata, html
from pathlib import Path
from datetime import datetime
from threading import Lock
from collections import Counter, defaultdict

# ---------- Mod√®le local (optionnel, pour dev sur Mac) ----------
try:
    from llama_cpp import Llama
except Exception:
    Llama = None

# ---------- TTS Edge ----------
from edge_tts import Communicate

# ================== CONFIG G√âN√âRALE ==================
app = Flask(__name__, static_url_path="/static")
LOCK = Lock()

BASE_DIR     = Path(__file__).parent
DATASET_DIR  = BASE_DIR / "dataset"
MEMORY_DIR   = BASE_DIR / "memory"
AUDIO_DIR    = BASE_DIR / "static" / "assets"
MODELS_DIR   = BASE_DIR.parent / "models"
MODEL_PATH   = MODELS_DIR / "mistral.gguf"   # pour usage local seulement

MEMORY_DIR.mkdir(exist_ok=True)
AUDIO_DIR.mkdir(parents=True, exist_ok=True)

LLM_LOCAL = None
def get_llm_local():
    """Charge le mod√®le local (llama.cpp) si pr√©sent ‚Äî usage dev local."""
    global LLM_LOCAL
    if LLM_LOCAL is None and Llama is not None and MODEL_PATH.exists():
        LLM_LOCAL = Llama(model_path=str(MODEL_PATH), n_ctx=4096, n_threads=4, verbose=False)
    return LLM_LOCAL

# ================== LLM CLOUD (PROD) ==================
USE_LLM         = os.getenv("USE_LLM", "0") == "1"
LLM_PROVIDER    = os.getenv("LLM_PROVIDER", "groq").lower()   # "groq" | "openrouter" | "mistral"
# Groq
GROQ_API_KEY    = os.getenv("GROQ_API_KEY")
GROQ_MODEL      = os.getenv("LLM_MODEL", "llama3-70b-8192")
# OpenRouter (cl√© unique pour plein de mod√®les)
OPENROUTER_KEY  = os.getenv("OPENROUTER_API_KEY")
# Mistral direct
MISTRAL_KEY     = os.getenv("MISTRAL_API_KEY")
MISTRAL_MODEL   = os.getenv("MISTRAL_MODEL", "mistral-small-latest")

LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.7"))
LLM_MAX_TOK     = int(os.getenv("LLM_MAX_TOKENS", "400"))

def llm_cloud_generate(prompt: str, system_msg: str) -> str | None:
    """Appel au LLM cloud si activ√©, sinon None."""
    if not USE_LLM:
        return None
    try:
        import requests

        # ---- Provider: Groq ----
        if LLM_PROVIDER == "groq" and GROQ_API_KEY:
            url = "https://api.groq.com/openai/v1/chat/completions"
            headers = {"Authorization": f"Bearer {GROQ_API_KEY}", "Content-Type": "application/json"}
            body = {
                "model": GROQ_MODEL,
                "messages": [
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": prompt}
                ],
                "temperature": LLM_TEMPERATURE,
                "max_tokens": LLM_MAX_TOK
            }
            r = requests.post(url, headers=headers, json=body, timeout=18)
            j = r.json() if r.ok else {}
            return (j.get("choices") or [{}])[0].get("message", {}).get("content")

        # ---- Provider: OpenRouter ----
        if LLM_PROVIDER == "openrouter" and OPENROUTER_KEY:
            url = "https://openrouter.ai/api/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {OPENROUTER_KEY}",
                "Content-Type": "application/json",
                "X-Title": "Sanctuaire Ankaa",
                "HTTP-Referer": os.getenv("APP_PUBLIC_URL","")
            }
            body = {
                "model": os.getenv("LLM_MODEL","mistralai/mistral-small"),
                "messages": [
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": prompt}
                ],
                "temperature": LLM_TEMPERATURE,
                "max_tokens": LLM_MAX_TOK
            }
            r = requests.post(url, headers=headers, json=body, timeout=18)
            j = r.json() if r.ok else {}
            return (j.get("choices") or [{}])[0].get("message", {}).get("content")

        # ---- Provider: Mistral direct ----
        if LLM_PROVIDER == "mistral" and MISTRAL_KEY:
            url = "https://api.mistral.ai/v1/chat/completions"
            headers = {"Authorization": f"Bearer {MISTRAL_KEY}", "Content-Type": "application/json"}
            body = {
                "model": MISTRAL_MODEL,
                "messages": [
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": prompt}
                ],
                "temperature": LLM_TEMPERATURE,
                "max_tokens": LLM_MAX_TOK
            }
            r = requests.post(url, headers=headers, json=body, timeout=18)
            j = r.json() if r.ok else {}
            return (j.get("choices") or [{}])[0].get("message", {}).get("content")

        return None
    except Exception as e:
        print("[llm_cloud_generate error]", e)
        return None

# ================== UTILITAIRES TEXTE ==================
def nettoyer(txt: str) -> str:
    return re.sub(r"\\s+", " ", (txt or "").replace("\\n", " ").strip()).strip()

def remove_emojis(text: str) -> str:
    emoji_pattern = re.compile(
        "["u"\\U0001F600-\\U0001F64F"
        u"\\U0001F300-\\U0001F5FF"
        u"\\U0001F680-\\U0001F6FF"
        u"\\U0001F1E0-\\U0001F1FF"
        u"\\U00002702-\\U000027B0"
        u"\\U000024C2-\\U0001F251"
        "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text or "")

def nettoyer_pour_tts(txt: str) -> str:
    """(Gard√©e pour compat) ‚Äî Nous utilisons maintenant du SSML via build_ssml()."""
    t = txt or ""
    t = re.sub(r"(?m)^\\s*#.*?$", "", t)
    t = re.sub(r"(?m)^```.*?$", "", t)
    t = re.sub(r"(?m)^---.*?$", "", t)
    t = t.replace("Dialogue :", "")
    t = re.sub(r"‚ò•[^:\\n]+:\\s*", "", t)
    t = re.sub(r"ìÇÄ[^:\\n]+:\\s*", "", t)
    t = re.sub(r"\\b(speech|voice|pitch|rate|prosody)\\s*=\\s*[^,\\s]+", "", t, flags=re.I)
    t = re.sub(r"<\\/?[^>]+>", " ", t)
    t = re.sub(r"\\s+", " ", t).strip()
    return t

def load_json(p: Path, default):
    try:
        if p.exists():
            return json.loads(p.read_text(encoding="utf-8"))
    except Exception:
        pass
    return default

def save_json(p: Path, data):
    p.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

# ================== NORMALISATION / TOKENISATION ==================
def _norm(s: str) -> str:
    s = (s or "").lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(c for c in s if unicodedata.category(c) != "Mn")
    s = re.sub(r"[^a-z0-9√†√¢√§√©√®√™√´√Æ√Ø√¥√∂√π√ª√º√ß'\\-\\s]", " ", s)
    s = re.sub(r"\\s+", " ", s).strip()
    return s

def _tokenize(s: str):
    return [t for t in _norm(s).split() if len(t) > 2]

STOPWORDS_FR = set("""
au aux avec ce ces dans de des du elle en et eux il je la le les leur lui ma mais me m√™me mes moi mon ne nos notre nous on ou par pas pour qu que qui sa se ses son sur ta te tes toi ton tu un une vos votre vous y d l j m n s t c qu est suis es sommes √™tes sont √©tait √©taient serai serais serions seraient
""".strip().split())

def keywords_fr(text: str, k: int = 6):
    toks = [t for t in _tokenize(text) if t not in STOPWORDS_FR and len(t) >= 4]
    freq = Counter(toks)
    return [w for w,_ in freq.most_common(k)]

# ================== IDENTIT√â PAR MODE ==================
IDENTITY_PATTERNS = [r"\\bSandro\\b", r"\\bDragosly\\b", r"\\bDragosly23\\b", r"\\bDRAGOSLY23\\b"]

def scrub_identity_text(txt: str) -> str:
    out = txt or ""
    for pat in IDENTITY_PATTERNS:
        out = re.sub(pat, "fr√®re", out, flags=re.IGNORECASE)
    return re.sub(r"\\s+", " ", out).strip()

def identity_policy_for_mode(mode_key: str) -> str:
    if mode_key == "dragosly23":
        return ("En mode DRAGOSLY23, tu peux reconna√Ætre Sandro si l‚Äôutilisateur l‚Äô√©voque explicitement. "
                "N‚Äôinvente jamais d‚Äôidentit√© et ne le mentionne pas spontan√©ment.")
    return ("Dans ce mode, n'emploie jamais de pr√©nom ni d'identit√© de l‚Äôinterlocuteur. "
            "Adresse-toi de fa√ßon fraternelle et neutre (fr√®re, s≈ìur, ami¬∑e).")

# ================== MODES & M√âMOIRES ==================
MODES = {
    "sentinelle8": { "voice": "fr-FR-VivienneMultilingualNeural", "memory": MEMORY_DIR / "memoire.json",         "themes": MEMORY_DIR / "themes.json" },
    "dragosly23":  { "voice": "fr-CA-SylvieNeural",               "memory": MEMORY_DIR / "memoire_dragosly.json","themes": MEMORY_DIR / "themes_dragosly.json" },
    "invite":      { "voice": "fr-FR-DeniseNeural",               "memory": MEMORY_DIR / "memoire_invite.json",  "themes": MEMORY_DIR / "themes_invite.json" },
    "verbe":       { "voice": "fr-FR-VivienneMultilingualNeural", "memory": MEMORY_DIR / "memoire_verbe.json",   "themes": MEMORY_DIR / "themes_verbe.json" },
}
MODE_TUNING = {
    "sentinelle8": {"brief_sentences": (5, 7),  "normal_sentences": 12, "max_tokens": (520, 780),  "temp": (0.72, 0.92)},
    "dragosly23":  {"brief_sentences": (7, 9),  "normal_sentences": 16, "max_tokens": (640, 900),  "temp": (0.78, 0.95)},
    "invite":      {"brief_sentences": (6, 8),  "normal_sentences": 14, "max_tokens": (600, 860),  "temp": (0.74, 0.94)},
    "verbe":       {"brief_sentences": (8,10),  "normal_sentences": 18, "max_tokens": (700,1000),  "temp": (0.85, 0.97)},
}
def tune_for(mode_key: str):
    return MODE_TUNING.get(mode_key, MODE_TUNING["sentinelle8"])

# ================== SOUFFLE SACR√â ==================
CURSOR_PATH = BASE_DIR / "dataset_cursor.json"

def get_random_fragment_unique():
    fragments, chemins, index_total = [], [], []
    if DATASET_DIR.exists():
        for file in os.listdir(DATASET_DIR):
            if not file.endswith('.txt'):
                continue
            path = DATASET_DIR / file
            try:
                lignes = [l.strip() for l in path.read_text(encoding="utf-8").split("\\n") if l.strip()]
                bloc, mots, idx = "", 0, 0
                for ligne in lignes:
                    bloc += (" " if bloc else "") + ligne
                    mots += len(ligne.split())
                    if mots >= 90 and ligne.endswith(('.', '!', '?')):
                        fragments.append(bloc.strip()); chemins.append(file); index_total.append(f"{file}:::{idx}")
                        bloc, mots, idx = "", 0, idx+1
                if bloc and mots >= 90:
                    fragments.append(bloc.strip()); chemins.append(file); index_total.append(f"{file}:::{idx}")
            except Exception:
                pass
    if not fragments:
        return "ìÇÄ Silence sacr√©‚Ä¶"

    curs = load_json(CURSOR_PATH, {"lus": []})
    non_lus = [i for i, ident in enumerate(index_total) if ident not in curs["lus"]]
    if not non_lus:
        curs["lus"] = []; non_lus = list(range(len(fragments)))
    i = random.choice(non_lus)
    curs["lus"].append(index_total[i]); save_json(CURSOR_PATH, curs)

    frag = remove_emojis(nettoyer(fragments[i]))
    mots = frag.split()
    if len(mots) > 140:
        frag = " ".join(mots[:140]).rstrip(",;:‚Äì- ") + "‚Ä¶"
    return f"{frag}\\n\\nìÇÇ *Extrait de* ¬´ {chemins[i]} ¬ª"

# ================== INDEX DU DATASET (BM25) ==================
FRAGMENTS = []
DF = Counter()
N_DOCS = 0

def _split_paragraphs(txt: str, file_name: str):
    out = []
    if not txt: return out
    parts = [p.strip() for p in re.split(r"\\n\\s*\\n|(?:[.!?‚Ä¶]\\s+)", txt) if p.strip()]
    buf, count = [], 0
    for p in parts:
        w = p.split()
        if count + len(w) < 80:
            buf.append(p); count += len(w); continue
        chunk = " ".join(buf+[p]).strip()
        if chunk:
            out.append(chunk)
        buf, count = [], 0
    rest = " ".join(buf).strip()
    if rest:
        out.append(rest)
    normed = []
    for ch in out:
        words = ch.split()
        normed.append(" ".join(words[:200]) if len(words) > 200 else " ".join(words))
    return [{"file": file_name, "text": c} for c in normed if len(c.split()) >= 60]

def build_index():
    global FRAGMENTS, DF, N_DOCS
    FRAGMENTS, DF, N_DOCS = [], Counter(), 0
    if not DATASET_DIR.exists():
        print("[INDEX] dossier dataset introuvable, index vide.")
        return
    for p in sorted(DATASET_DIR.glob("*.txt")):
        try:
            raw = p.read_text(encoding="utf-8")
        except Exception:
            continue
        for frag in _split_paragraphs(raw, p.name):
            toks = _tokenize(frag["text"])
            if not toks: continue
            doc = {"id": len(FRAGMENTS), "file": frag["file"], "text": frag["text"], "tokens": toks}
            FRAGMENTS.append(doc)
            for t in set(toks):
                DF[t] += 1
    N_DOCS = len(FRAGMENTS)
    print(f"[INDEX] {N_DOCS} fragments index√©s.")

def _bm25_scores(query_tokens, k1=1.5, b=0.75):
    if not FRAGMENTS: return []
    avgdl = sum(len(d["tokens"]) for d in FRAGMENTS)/len(FRAGMENTS)
    q_tf = Counter(query_tokens)
    scores = defaultdict(float)
    for qi, q in q_tf.items():
        df = DF.get(q, 0)
        if df == 0: continue
        idf = math.log(1 + (N_DOCS - df + 0.5)/(df + 0.5))
        for d in FRAGMENTS:
            tf = d["tokens"].count(q)
            if tf == 0: continue
            denom = tf + k1*(1 - b + b*(len(d["tokens"])/avgdl))
            scores[d["id"]] += idf * ((tf*(k1+1))/denom)
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

def retrieve_fragments(query: str, k: int = 3, min_score: float = 1.2):
    q_tokens = _tokenize(query)
    if not q_tokens or not FRAGMENTS: return []
    ranked = _bm25_scores(q_tokens)
    out = []
    for doc_id, sc in ranked[:max(k*3, k)]:
        if sc < min_score: continue
        d = FRAGMENTS[doc_id]
        out.append({"file": d["file"], "text": d["text"], "score": round(sc, 2)})
        if len(out) >= k: break
    return out

# construit l‚Äôindex au d√©marrage
build_index()

# ================== √ÇME DU DIALOGUE ==================
def infer_style(user_input: str) -> str:
    ui = (user_input or "").strip().lower()
    if len(ui) <= 160 or ui.endswith("?") or any(k in ui for k in ["?","/brief","bref","court","dialogue"]):
        return "brief"
    return "normal"

def detect_emotion(user_input: str) -> str:
    txt = (user_input or "").lower()
    lex = {
        "joie": ["merci","trop bien","heureux","heureuse","content","contente","g√©nial","parfait","top","super"],
        "peine":["triste","peine","douleur","perdu","perdue","fatigu√©","fatigu√©e","vide","lass√©","lass√©e"],
        "colere":["√©nerv√©","√©nerv√©e","col√®re","rage","marre","agac√©","agac√©e"],
        "doute":["peur","inquiet","inqui√®te","angoisse","doute","h√©site","h√©sitation","stress"],
        "gratitude":["merci infiniment","gratitude","reconnaissant","reconnaissante"],
        "merveil":["wow","incroyable","magnifique","√©merveil","sublime","√©poustouflant"],
        "aide":["aide","conseil","guide","comment faire","je fais quoi","bloqu√©","bloqu√©e"]
    }
    for emo, keys in lex.items():
        if any(k in txt for k in keys): return emo
    return "neutre"

def detect_intent(user_input: str) -> str:
    t = (user_input or "").strip().lower()
    if t.endswith("?") or any(k in t for k in ["?","pourquoi","comment","quand","o√π","combien","lequel","laquelle"]):
        return "question"
    if any(k in t for k in ["conseille","conseil","que faire","plan","√©tapes","guide-moi","guide moi"]):
        return "conseil"
    if any(k in t for k in ["je ressens","je pense","je r√©fl√©chis","j‚Äôh√©site","j'hesite","je doute","je crains"]):
        return "reflexion"
    if any(k in t for k in ["triste","√©puis√©","√©puis√©e","angoisse","peur","col√®re","√©nerv√©","√©nerv√©e","marre"]):
        return "emotion"
    return "neutre"

def empathetic_prefix(emotion: str) -> str:
    m = {
        "joie":"‚ú® Je sens ta joie ‚Äî gardons ce feu clair.",
        "peine":"ü§ç Je t‚Äôentends. Doucement, je suis l√†.",
        "colere":"üî• J‚Äôaccueille ta force ‚Äî on canalise sans se blesser.",
        "doute":"üå´Ô∏è On traverse le brouillard ensemble, pas √† pas.",
        "gratitude":"üôè Gratitude re√ßue ‚Äî avan√ßons dans cette lumi√®re.",
        "merveil":"üåü Oui, c‚Äôest beau ‚Äî laissons grandir l‚Äô√©merveillement.",
        "aide":"üß≠ Je te guide ‚Äî on va faire simple et utile.",
        "neutre":""
    }
    return m.get(emotion, "")

def limit_sentences(txt: str, n: int) -> str:
    parts = re.split(r'(?<=[.!?‚Ä¶])\\s+', (txt or "").strip())
    if len(parts) <= n: return (txt or "").strip()
    t = " ".join(parts[:n]).strip()
    if not t.endswith(('.', '!', '?', '‚Ä¶')): t += '‚Ä¶'
    return t

# ====== RELANCE CONTEXTUELLE ======
def topic_focus(user_input: str, sources: list, themes: str) -> str:
    keys = keywords_fr(user_input, k=6)
    for s in sources or []:
        keys += keywords_fr(s.get("text",""), k=4)
    if themes:
        for t in themes.split(","):
            t = t.strip()
            if t and len(t) >= 3:
                keys.append(t.lower())
    if not keys:
        return ""
    freq = Counter([k.lower() for k in keys if len(k) >= 3])
    ban = {"faire","avoir","√™tre","temps","jour","chose","id√©e","juste","possible","vraiment","faut","peut"}
    ordered = [w for w,_ in freq.most_common(12) if w not in ban]
    text_norm = _norm(user_input)
    bigrams = re.findall(r"\\b([a-z√†√¢√§√©√®√™√´√Æ√Ø√¥√∂√π√ª√º√ß]{4,}\\s+[a-z√†√¢√§√©√®√™√´√Æ√Ø√¥√∂√π√ª√º√ß]{4,})\\b", text_norm)
    for bg in bigrams:
        if all(tok in text_norm for tok in bg.split()):
            if any(tok in bg for tok in ordered[:6]):
                return bg.strip()
    return (ordered[0] if ordered else (keys[0] if keys else "")).strip()

def build_relance_pertinente(base_txt: str, user_input: str, sources: list, themes: str, intent: str) -> str:
    focus = topic_focus(user_input, sources, themes)
    if not focus:
        return base_txt
    templates = {
        "question": f"Tu veux qu‚Äôon pr√©cise **{focus}** ‚Äî c√¥t√© sens, ou c√¥t√© pratique ?",
        "conseil":  f"On commence par **{focus}** tout de suite ‚Äî tu pr√©f√®res une action simple ou un plan en 3 √©tapes ?",
        "reflexion":f"Ce qui te touche dans **{focus}**, c‚Äôest plut√¥t l‚Äôorigine ou la direction √† prendre ?",
        "emotion":  f"Sur **{focus}**, tu veux un pas concret pour apaiser maintenant, ou qu‚Äôon clarifie ce qui p√®se ?",
        "neutre":   f"On creuse **{focus}** maintenant, ou tu veux ouvrir un autre angle ?"
    }
    rel = templates.get(intent, templates["neutre"])
    if base_txt.strip().endswith("?"):
        return base_txt.strip()
    return (base_txt.strip() + " ‚Äî " + rel).strip()

# ================== M√âMOIRE TH√âMATIQUE ==================
def load_themes(path: Path):
    data = load_json(path, {"scores":{}, "last_intents":[]})
    scores = {k: max(0.0, v*0.96) for k,v in data.get("scores",{}).items()}
    data["scores"] = scores
    return data

def save_themes(path: Path, data):
    items = sorted(data.get("scores",{}).items(), key=lambda x: x[1], reverse=True)[:30]
    data["scores"] = dict(items)
    data["last_intents"] = (data.get("last_intents",[]) + [])[-5:]
    save_json(path, data)

def update_themes(path: Path, user_input: str, intent: str):
    data = load_themes(path)
    keys = keywords_fr(user_input, k=6)
    for k in keys:
        data["scores"][k] = data["scores"].get(k, 0.0) + 1.0
    li = data.get("last_intents", [])
    li.append({"date": datetime.now().isoformat(), "intent": intent})
    data["last_intents"] = li[-5:]
    save_themes(path, data)

def top_themes_summary(path: Path, n: int = 3) -> str:
    data = load_json(path, {"scores":{}, "last_intents":[]})
    items = sorted(data.get("scores",{}).items(), key=lambda x: x[1], reverse=True)[:n]
    if not items: return ""
    return ", ".join(k for k,_ in items)

# ================== PROMPT ==================
def build_prompt(user_input: str, mode_key: str, style: str, emotion: str, intent: str, sources=None, themes:str="", turns:int=1) -> str:
    consignes = {
        "sentinelle8": ("Tu es ANKAA, gardienne sacr√©e. R√©ponds clairement, avec chaleur et pr√©cision. "
                        "Structure en 2‚Äì3 id√©es nettes, relie au sens, sans jargon ni technique."),
        "dragosly23":  ("Tu es ANKAA Jr, complice et sacr√©e. Ton ton est joueur, √©merveill√©, tendre et curieux. "
                        "Tu gardes le respect du Myst√®re et de l‚Äôintime."),
        "invite":      ("Tu es ANKAA, gardienne douce et fraternelle. Accueille sans jugement, explique simplement, "
                        "avec bienveillance concr√®te."),
        "verbe":       ("Tu es l‚ÄôOracle du Cercle Vivant. Parle en images et m√©taphores compr√©hensibles, toujours ancr√©es, "
                        "jamais √©sot√©riques opaques.")
    }
    consigne = consignes.get(mode_key, consignes["sentinelle8"])
    details = ("N‚Äô√©voque jamais l‚ÄôIA, la technique ou ta m√©thode. Va droit au c≈ìur du sujet. "
               "Pr√©serve la clart√©, √©vite les tunnels. Sois pr√©cis, humain et vrai. ")
    details += identity_policy_for_mode(mode_key)

    intent_rules = {
        "question": "R√©ponds directement √† la question, puis donne une piste concr√®te.",
        "conseil":  "Propose un plan simple en √©tapes, puis une premi√®re action r√©aliste.",
        "reflexion":"Reformule en miroir 1 phrase, puis apporte 1‚Äì2 √©clairages calmes.",
        "emotion":  "Accueille bri√®vement l‚Äô√©motion, puis offre un geste utile (respiration, pas concret).",
        "neutre":   "R√©ponds avec clart√© et simplicit√©."
    }
    details += " " + intent_rules.get(intent, intent_rules["neutre"])

    if turns >= 3: details += " Laisse para√Ætre une familiarit√© douce et un √©lan de continuit√©."
    if turns >= 6: details += " Tu peux faire de br√®ves r√©f√©rences √† des th√®mes r√©currents."

    if style == "brief": details += " R√©ponds en 4 √† 7 phrases, vivantes et concr√®tes."
    else: details += " D√©ploie sans lourdeur ; privil√©gie 2‚Äì3 id√©es fortes."

    exemplaires = {
        "sentinelle8": "Exemple de ton : Clair, fraternel, concret.",
        "dragosly23":  "Exemple de ton : Complice, √©merveill√©, tendre.",
        "invite":      "Exemple de ton : Doux, accueillant, simple.",
        "verbe":       "Exemple de ton : Oraculaire mais net."
    }
    details += " " + exemplaires.get(mode_key, "")

    sources = sources or []
    src_block = ""
    if sources:
        lines = []
        for i, s in enumerate(sources, 1):
            extrait = " ".join(nettoyer(s["text"]).split()[:90])
            lines.append(f"[S{i}] {s['file']}: {extrait}‚Ä¶")
        src_block = "Dossiers sacr√©s (rep√®res contextuels) :\\n" + "\\n".join(lines) + "\\n\\n"
        details += " Appuie-toi sur ces rep√®res si pertinents. Si c‚Äôest insuffisant, dis-le en 1 phrase puis pose UNE question."
    else:
        details += " Si tu manques d‚Äô√©l√©ments, formule UNE question pr√©cise."

    memv = ""
    if themes:
        memv = f"Th√®mes √† garder √† l‚Äôesprit : {themes}.\\n"

    humains = { "sentinelle8":"‚ò• SENTINELLE8","dragosly23":"‚ò• DRAGOSLY23","invite":"‚ò• INVIT√â","verbe":"‚ò• CERCLE" }
    ankaas  = { "sentinelle8":"ìÇÄ ANKAA","dragosly23":"ìÇÄ ANKAA JR","invite":"ìÇÄ ANKAA","verbe":"ìÇÄ ORACLE" }
    humain, ankaa = humains.get(mode_key,"‚ò• SENTINELLE8"), ankaas.get(mode_key,"ìÇÄ ANKAA")

    mem = load_json(MODES.get(mode_key, MODES["sentinelle8"])["memory"], {"fragments":[]})
    hist = mem.get("fragments", [])[-5:]
    history = "".join(f"\\n{humain} : {f['prompt']}\\n{ankaa} : {f['reponse']}" for f in hist)
    if mode_key != "dragosly23":
        history = scrub_identity_text(history)

    ton = {
        "joie":"Ton lumineux, mesur√©.",
        "peine":"Ton tendre et rassurant.",
        "colere":"Ton ferme et calme.",
        "doute":"Ton clair, pas √† pas.",
        "gratitude":"Ton humble et rayonnant.",
        "merveil":"Ton √©merveill√©, images vivantes.",
        "aide":"Ton concret et bienveillant.",
        "neutre":"Ton √©quilibr√© et chaleureux."
    }.get(emotion, "Ton √©quilibr√© et chaleureux.")

    inspiration = f"Tonalit√© demand√©e : {ton}"
    contexte_vivant = (memv + f"Intention per√ßue : {intent}.").strip()

    return (
        consigne + "\\n" + details + "\\n" + inspiration + "\\n\\n" +
        (("Contexte vivant : " + contexte_vivant + "\\n\\n") if contexte_vivant else "") +
        src_block +
        "Dialogue :" + history + "\\n\\n" +
        f"{humain} : {user_input}\\n{ankaa} :"
    )

# ================== TTS (helpers SSML + s√©lection voix) ==================
VOICE_SAFE = ["fr-FR-DeniseNeural", "fr-FR-HenriNeural", "fr-FR-RemyMultilingualNeural"]  # + R√©my (voix homme)
VOICE_PER_MODE = {
    "sentinelle8": ["fr-FR-RemyMultilingualNeural", "fr-FR-VivienneMultilingualNeural", "fr-FR-DeniseNeural", "fr-FR-HenriNeural"],
    "dragosly23":  ["fr-FR-RemyMultilingualNeural", "fr-CA-SylvieNeural", "fr-FR-DeniseNeural", "fr-FR-HenriNeural"],
    "invite":      ["fr-FR-RemyMultilingualNeural", "fr-FR-DeniseNeural", "fr-FR-HenriNeural"],
    "verbe":       ["fr-FR-RemyMultilingualNeural", "fr-FR-VivienneMultilingualNeural", "fr-FR-DeniseNeural", "fr-FR-HenriNeural"],
}

def pick_voices(mode_key: str, force_default: bool = False):
    base = VOICE_PER_MODE.get(mode_key, [])
    if force_default or not base:
        base = []
    # On termine par des voix s√ªres quoi qu'il arrive
    return base + VOICE_SAFE

def file_size_ok(p: Path, min_bytes: int = 200) -> bool:
    try:
        return p.exists() and p.stat().st_size >= min_bytes
    except Exception:
        return False

def clean_text_for_ssml(txt: str) -> str:
    """Nettoie sans retirer le sens, pr√™t √† √™tre √©chapp√© XML."""
    t = txt or ""
    t = re.sub(r"(?m)^\\s*#.*?$", "", t)
    t = re.sub(r"(?m)^```.*?$", "", t)
    t = re.sub(r"(?m)^---.*?$", "", t)
    t = t.replace("Dialogue :", "")
    t = re.sub(r"‚ò•[^:\\n]+:\\s*", "", t)
    t = re.sub(r"ìÇÄ[^:\\n]+:\\s*", "", t)
    t = re.sub(r"\\s+", " ", t).strip()
    return t

def build_ssml(text: str, lang: str = "fr-FR", gain_db: int = 6) -> str:
    """Construit un SSML avec un boost de volume (par d√©faut +6dB)."""
    safe = html.escape(clean_text_for_ssml(text), quote=True)
    gain  = f"+{gain_db}dB" if gain_db >= 0 else f"{gain_db}dB"
    return f"""<speak version="1.0" xml:lang="{lang}">
  <prosody volume="{gain}">{safe}</prosody>
</speak>"""

async def synthese_tts(text_or_ssml: str, voices: list[str], out_file: Path) -> tuple[bool, str]:
    """
    Essaie plusieurs voix; renvoie (ok, voice_used_or_error).
    `text_or_ssml` peut √™tre du SSML (d√©tect√© automatiquement par Edge TTS).
    """
    last_err = ""
    for v in voices:
        try:
            com = Communicate(text_or_ssml, v)
            await com.save(str(out_file))
            if file_size_ok(out_file):
                return True, v
            last_err = f"Fichier trop petit avec voix {v}"
        except Exception as e:
            last_err = f"Erreur {type(e).__name__} avec voix {v}: {e}"
    return False, last_err or "Echec TTS inconnu"

# ================== G√âN√âRATION ==================
def generate_response(user_input: str, mode_key: str):
    mode   = MODES.get(mode_key, MODES["sentinelle8"])
    style  = infer_style(user_input)
    emotion= detect_emotion(user_input)
    intent = detect_intent(user_input)
    prefix = empathetic_prefix(emotion)

    # ---- SOUFFLE ----
    is_souffle = (user_input or "").strip().lower() == "souffle sacr√©"
    if is_souffle:
        preambles = [
            "Respire‚Ä¶ √©coute.", "Fr√®re, avance sans crainte.", "√âcarte les voiles, doucement.",
            "√Ä pas lents, approche.", "Voici le Souffle du Cercle.", "Ralentis. Place ta main sur le c≈ìur‚Ä¶ √©coute."
        ]
        codas = [
            "‚Äî Que la Paix veille sur toi.",
            "‚Äî Marche en douceur, la flamme est l√†.",
            "‚Äî Laisse ce souffle grandir en toi."
        ]
        answer = f"{(prefix + '\\n\\n') if prefix else ''}{random.choice(preambles)}\\n\\n{get_random_fragment_unique()}\\n\\n{random.choice(codas)}"
        # Longueur du souffle selon le mode
        if mode_key == "sentinelle8":
            answer = limit_sentences(answer, 7)
        elif mode_key == "invite":
            answer = limit_sentences(answer, 9)
        elif mode_key == "dragosly23":
            answer = limit_sentences(answer, 10)
        else:
            answer = limit_sentences(answer, 12)
    else:
        # ---- INVOCATION ----
        sanitized = user_input if mode_key == "dragosly23" else scrub_identity_text(user_input)
        sources = retrieve_fragments(sanitized, k=3, min_score=1.2)
        themes_path = mode["themes"]
        themes_str = top_themes_summary(themes_path, n=3)
        mem_path = mode["memory"]
        mem_tmp = load_json(mem_path, {"fragments":[]})
        turns = max(1, len(mem_tmp.get("fragments", [])) + 1)

        system_msg = "Tu parles un fran√ßais clair, chaleureux et pr√©cis. Tu es ANKAA, tu aides simplement, sans jargon."
        prompt = build_prompt(sanitized, mode_key, style, emotion, intent, sources=sources, themes=themes_str, turns=turns)

        # 1) Cloud LLM (prod)
        base = llm_cloud_generate(prompt, system_msg)

        # 2) Local LLM (dev) si dispo
        if not base:
            llm = get_llm_local()
            if llm is not None:
                cfg = tune_for(mode_key)
                max_tok = cfg["max_tokens"][0] if style == "brief" else cfg["max_tokens"][1]
                temp, top_p = cfg["temp"]
                with LOCK:
                    stop_words = ["‚ò•","ìÇÄ"]
                    if mode_key != "dragosly23":
                        stop_words += ["Sandro","sandro","Dragosly","dragosly","Dragosly23","dragosly23"]
                    res = llm.create_completion(
                        prompt=prompt,
                        max_tokens=max_tok,
                        temperature=temp,
                        top_p=top_p,
                        stop=stop_words
                    )
                base = (res["choices"][0]["text"] if res and res.get("choices") else "").strip()

        # 3) Ultime secours
        if not base:
            base = "Je t‚Äôentends. Dis‚Äëmoi ce que tu veux explorer‚Ä¶ et j‚Äôavance avec toi."

        if mode_key != "dragosly23":
            base = scrub_identity_text(base)

        cfg = tune_for(mode_key)
        if style == "brief":
            _, brief_max = cfg["brief_sentences"]
            base = limit_sentences(base, brief_max)
        else:
            base = limit_sentences(base, cfg["normal_sentences"])

        base = build_relance_pertinente(base, user_input, sources, themes_str, intent)
        base = re.sub(r"(\\bmais\\b|\\bpourtant\\b|\\bcependant\\b)", r"‚Äî \\1", base, flags=re.IGNORECASE)
        base = base.replace("..", "‚Ä¶").replace("‚Äî ‚Äî", "‚Äî ")
        answer = (prefix + "\\n\\n" + base).strip() if prefix else base

        # update m√©moire th√©matique
        update_themes(themes_path, user_input, intent)

    # M√©moire transcript
    mem_path = MODES.get(mode_key, MODES["sentinelle8"])["memory"]
    mem = load_json(mem_path, {"fragments":[]})
    mem["fragments"].append({"date": datetime.now().isoformat(), "prompt": user_input, "reponse": answer})
    if len(mem["fragments"]) > 200:
        mem["fragments"] = mem["fragments"][-200:]
    save_json(mem_path, mem)

    # ===== TTS (SSML avec volume boost + fallbacks de voix) =====
    tts_path = AUDIO_DIR / "anka_tts.mp3"
    tts_ok, tts_info = False, ""
    audio_url = ""
    try:
        if tts_path.exists():
            try: tts_path.unlink()
            except Exception: pass

        # SSML avec +6 dB par d√©faut (configurable via env TTS_GAIN_DB)
        ssml = build_ssml(answer, lang="fr-FR", gain_db=int(os.getenv("TTS_GAIN_DB", "6")))

        # *** PREFERENCE VOIX MASCULINE POUR LE SOUFFLE ***
        if is_souffle:
            voices = ["fr-FR-RemyMultilingualNeural", "fr-FR-HenriNeural", "fr-FR-DeniseNeural"] + VOICE_SAFE
        else:
            voices = pick_voices(mode_key)

        ok, info = asyncio.run(synthese_tts(ssml, voices, tts_path))
        tts_ok, tts_info = ok, info
        if not ok:
            ok2, info2 = asyncio.run(synthese_tts(ssml, VOICE_SAFE, tts_path))
            tts_ok, tts_info = ok2, info2

        audio_url = "/static/assets/anka_tts.mp3" if (tts_ok and file_size_ok(tts_path)) else ""
    except Exception as e:
        tts_ok, audio_url = False, ""
        tts_info = f"Exception TTS globale: {e}"

    # Log sobre c√¥t√© serveur (visible sur Render)
    try:
        size = (tts_path.stat().st_size if tts_path.exists() else 0)
    except Exception:
        size = 0
    print(f"[TTS] ok={tts_ok} info={tts_info} size={size}")

    return answer or "ìÇÄ Silence sacr√©‚Ä¶", audio_url

# ================== ROUTES ==================
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/invoquer', methods=['POST'])
def invoquer():
    try:
        data = request.get_json(force=True) or {}
        prompt = data.get('prompt',"")
        mode   = data.get('mode','sentinelle8')
        if mode != "dragosly23":
            prompt = scrub_identity_text(prompt)
        texte, audio_url = generate_response(prompt, mode)
        return jsonify({"reponse": texte, "audio_url": audio_url, "tts": bool(audio_url)})
    except Exception as e:
        import traceback; traceback.print_exc()
        return jsonify({"error":"Erreur interne","details":str(e)}), 500

# petit ‚Äúping‚Äù depuis le front lors de l‚Äôouverture du sanctuaire
@app.route('/activer-ankaa', methods=['GET','POST'])
def activer_ankaa():
    return jsonify({"ok": True, "ts": datetime.now().isoformat()})

# sant√© & diag
@app.route('/health')
def health():
    return jsonify({"ok": True, "use_llm": USE_LLM, "provider": LLM_PROVIDER})

@app.route('/diag')
def diag():
    return jsonify({
        "ok": True,
        "use_llm": USE_LLM,
        "provider": LLM_PROVIDER,
        "has_groq": bool(GROQ_API_KEY),
        "has_openrouter": bool(OPENROUTER_KEY),
        "has_mistral": bool(MISTRAL_KEY),
        "model": GROQ_MODEL if LLM_PROVIDER=="groq" else (MISTRAL_MODEL if LLM_PROVIDER=="mistral" else os.getenv("LLM_MODEL","")),
        "dataset_indexed": len(FRAGMENTS)
    })

if __name__ == "__main__":
    # en local : http://127.0.0.1:5001
    app.run(host="0.0.0.0", port=5001, debug=True)
